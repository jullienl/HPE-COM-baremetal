---
# Performing automated ESXi 8.0 U2 installation on HPE Compute Ops Managmeent server(s) using an auto-generated ISO file with customized kickstart.
#
# Command that can be used to run this playbook:
#    $ ansible-playbook -i hosts ESXi80_provisioning.yml --ask-vault-password --ask-become-pass
#>


 # Adding a DNS record for the server that will be provisioned in the defined DNS server

#-------------------------------------- DNS record --------------------------------------------------------------------------------------------------------------------

- name: Creating a DNS record for the bare metal ESXi server
  hosts: ESX
  gather_facts: no
  vars:
    ansible_forks: 5
  vars_files:
    - vars/Windows_DNS_vars_encrypted.yml
  tasks:
    - name: Adding '{{ inventory_hostname }}' with '{{ os_ip_address }}' on '{{ dns_server }}' in '{{ domain }}' DNS domain
      community.windows.win_dns_record:
        name: "{{ inventory_hostname }}"
        type: "A"
        value: "{{ os_ip_address }}"
        zone: "{{ domain }}"
        state: present
      delegate_to: "{{ dns_server }}"


- name: Performing automated ESXi 8.0 U2 installation on HPE Compute Ops Managmeent server(s) using an auto-generated ISO file with customized kickstart.
  hosts: ESX
  gather_facts: no
  vars_files:
    - vars/ESXi8.0.u2_vars.yml
    - vars/GLCP_US_West_credentials_encrypted.yml    
    - vars/VMware_vCenter_vars_encrypted.yml
  vars:
    inventory_fqdn: "{{ inventory_hostname | lower }}.{{ domain }}"
    # ansible_python_interpreter: /usr/bin/python3
    ansible_host_key_checking: false
    validate_certs: false
    ssh_known_hosts_file: "{{ lookup('env','HOME') + '/.ssh/known_hosts' }}"
    ansible_ssh_public_key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
    ansible_forks: 5

  tasks:

#--------------------------------------Capture start time--------------------------------------------------------------------------------------------------------------

  - name: Gather subset facts on localhost
    setup:
      gather_subset: [all]
    delegate_to: localhost

  - name: Capture the start time (will be used later to filter COM activities and get the runtime of the playbook)
    set_fact:
      start_time: "{{ ansible_date_time.iso8601 }}"
      # yesterday_date: "{{ '%Y-%m-%dT%H:%M:%SZ' | strftime(ansible_date_time.epoch | int - (24 * 3600)) }}"
  
  - debug: var=start_time
      

#--------------------------------------Authentication with COM---------------------------------------------------------------------------------------------------------

  - name: Create HPE Compute Ops Management session
    import_tasks: files/Create_COM_session.yml


#--------------------------------------Capture COM resource API versions ----------------------- ----------------------------------------------------------------------

  - name: Capture Resource API versions
    import_tasks: files/Get_resource_API_versions.yml


#--------------------------------------Capture server information -----------------------------------------------------------------------------------------------------

  - name: Capture server '{{ serial_number }}' information
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ servers_API_version }}/servers?filter=hardware/serialNumber%20eq%20'{{ serial_number }}'"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server
    delegate_to: localhost

  # - debug: var=server

  - name: Exit if server '{{ serial_number }}' does not exist
    fail:
      msg: "Server '{{ serial_number }}' does not exist!"
    when: server.json.count == 0

  - name: Capture server '{{ serial_number }}' id, uri, connection status and iLO IP
    set_fact:
      server_id:  "{{ server | json_query('json.items[0].id') }}"
      server_uri:  "{{ server | json_query('json.items[0].resourceUri') }}"
      server_connected_status:  "{{ server | json_query('json.items[0].state.connected') }}"
      server_ilo_ip:  "{{ server | json_query('json.items[0].hardware.bmc.ip') }}"

  - debug: 
      msg:
        - "ID: {{ server_id }}"
        - "URI: {{ server_uri }}"
        - "Connection status: {{ server_connected_status }}"
        - "iLO IP: {{ server_ilo_ip }}"

  - name: Exit if server '{{ serial_number }}' is not connected to COM
    fail:
      msg: 
        - "Server '{{ serial_number }}' is not connected to COM!" 
        - "Make sure to connect the server's iLO to COM ! Go to iLO UI / Management / Compute Ops Management"
    when: server_connected_status == false

  - name: Wait until the server '{{ serial_number }}' raw inventory information is available (necessary when the server has recently been added to COM) then capture the data
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ servers_API_version }}/servers/{{ server_id }}/raw-inventory"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_raw_inventory
    failed_when: server_raw_inventory.status != 200 and server_raw_inventory.status != 404
    until: server_raw_inventory.status == 200 
    retries: 30
    delay: 60
    delegate_to: localhost
    
  - name: Wait until the complete discovery of server '{{ serial_number }}' is complete (necessary when the server has recently been added to COM).
    uri:
      url: "{{ ConnectivityEndpoint }}/ui-doorway/compute/v2/servers/{{ server_id }}"
      method: GET
      return_content: yes
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_inventory_from_ui_doorway
    until: server_inventory_from_ui_doorway.json.state_ != "Retrieving server information in progress" 
    retries: 30
    delay: 60
    delegate_to: localhost
    

#--------------------------------------Create internal storage settings -----------------------------------------------------------------------------------------------

  - name: Wait until PCI devices information is available then capture the server '{{ serial_number }}' raw inventory information 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ servers_API_version }}/servers/{{ server_id }}/raw-inventory"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_raw_inventory
    until: (server_raw_inventory.json.pciDevices | length>0)
    retries: 30
    delay: 60
    delegate_to: localhost

  # Is the server equipped with an NVMe NS204i boot controller?

  - name: Capture the presence of a NS204i NVMe boot controller in server '{{ serial_number }}'
    set_fact:
      NS204i_data: "{{ matched_item }}"
    vars:
        matched_item: "{{ item }}"
    loop: "{{ server_raw_inventory.json.pciDevices }}"
    loop_control:
      label: never
    when: item.Name is search('NS204i') 

  # - debug: var=NS204i_data

  - debug:
     msg: "NS204i found in server '{{ serial_number }}'! NVMe RAID1 volume will be used as the landing volume for the installation of ESXi!"
    when: NS204i_data is defined
  
  - debug:
     msg: "No NS204i found in server '{{ serial_number }}'! Let's check if a storage controller with drives is available..."
    when: NS204i_data is undefined

  # - debug: var=server_raw_inventory.json.storageInventory

  - name: Capture size of the NS204i RAID1 volume if any
    set_fact:
      boot_drive_bytes_size: "{{ matched_item }}"
    vars:
        matched_item: "{{ item.value.Volumes.Members[0].CapacityBytes }}"
    loop: "{{ server_raw_inventory.json.storageInventory | dict2items }}"
    loop_control:
      label: never
    when: NS204i_data is defined and item.value.Name is search('NS204i')
    
  - debug: 
      msg: "Size of NS204i volume: {{ ((boot_drive_bytes_size | int) / (1024 ** 3)) | round(1) }} GB"
    when: NS204i_data is defined 

  # Is the server equipped with an HPE MR or SR controller and with drives available?

  - name: Capture storage RAID controller information when an HPE MR or SR controller is used with available drives
    set_fact:
      storage_controller_data: "{{ matched_item }}"
    vars:
        matched_item: "{{ item.value }}"
    loop: "{{ server_raw_inventory.json.storageInventory | dict2items }}"
    loop_control:
      label: never
    when: NS204i_data is undefined and item.value.Drives | length > 0 and (item.value.Name is search('HPE MR') or item.value.Name is search('HPE SR'))

  # - debug: var=storage_controller_data

  - name: Set a variable for the name of the storage RAID controller found
    set_fact:
      storage_controller_name: "{{ storage_controller_data.Name }}"
    when: NS204i_data is undefined and storage_controller_data is defined
    
  - debug: 
      msg: "Storage RAID controller found: '{{ storage_controller_name }}' with '{{ storage_controller_data.Drives | length }}' drives"
    when: NS204i_data is undefined and storage_controller_data is defined

  - name: Exit when no NS204i and no SR/MR controller is found
    fail: 
      msg: "Error ! No NS204i and no SR/MR controller with disk available found !"
    when: NS204i_data is undefined and storage_controller_data is undefined

  - name: Set a controller type variable for kickstart creation when a NS204i is present
    set_fact:
      Controller_type: "NS204i"
    when: NS204i_data is defined 

  - name: Set a controller type variable for kickstart creation when there is no NS204i but an SR/MR controller is present.
    set_fact:
      Controller_type: "SR/MR controller"
    when: NS204i_data is undefined and storage_controller_data is defined

  - name: Check if server settings '{{ raid_type }}' already exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars:
      filter: "name eq '{{ raid_type }}'"
    register: internal_storage_server_setting
    when: NS204i_data is undefined
    delegate_to: localhost

  # - debug: var=internal_storage_server_setting

  # If NS204i NVMe boot controller is found then no need to set a RAID internal storage configuration
  # If NS204i NVMe boot controller is not found then need to set a RAID internal storage configuration
 
  - name: Create internal storage configuration using '{{ raid_type }}' with a volume size of '{{ volume_size_in_GB }}' GB for the OS boot volume when it does not exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name: "{{ raid_type }}"
        description: "Local storage settings using {{ raid_type }} for OS"
        platformFamily: "Any"
        category:  "STORAGE"
        settings:
          DEFAULT:
            raidType:  "{{ raid_type }}"         
            volumeSizeInGB: "{{ volume_size_in_GB }}"
    register: internal_storage_server_setting_result
    delegate_to: localhost
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 0

  - name: Result of the '{{ raid_type }}' creation task
    debug: var=internal_storage_server_setting_result
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 0

  - name: Set a variable for the resourceUri of the internal storage configuration '{{ raid_type }}' just created
    set_fact: 
      internal_storage_server_setting_resourceuri: "{{ internal_storage_server_setting_result.json.resourceUri }}"
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 0

  - name: Update internal storage configuration using '{{ raid_type }}' with a volume size of '{{ volume_size_in_GB }}' GB for the OS boot volume 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings/{{ internal_storage_server_setting_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ raid_type }}"
        description: "Local storage settings using {{ raid_type }} for OS"
        platformFamily: "Any"
        category:  "STORAGE"
        settings:
          DEFAULT:
            raidType:  "{{ raid_type }}"         
            volumeSizeInGB: "{{ volume_size_in_GB }}"
    vars: 
      internal_storage_server_setting_id: "{{ internal_storage_server_setting  | json_query('json.items[0].id') }}"
    register: internal_storage_server_setting_result
    delegate_to: localhost
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 1

  - name: Result of the '{{ raid_type }}' update task
    debug: var=internal_storage_server_setting_result.msg
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 1

  - name: Set a variable for the resourceUri of the internal storage configuration '{{ raid_type }}' just updated
    set_fact: 
      internal_storage_server_setting_resourceuri: "{{ internal_storage_server_setting | json_query('json.items[0].resourceUri') }}"
    when:  NS204i_data is undefined and internal_storage_server_setting.json.count == 1  

  - debug: var=internal_storage_server_setting_resourceuri
    when:  NS204i_data is undefined


#--------------------------------------Check BIOS/Workload profile settings -------------------------------------------------------------------------------------------

  # BIOS/Workload profiles are predefined by HPE, so there's no need to create/update them, just check that they exist. 

  - name: Check if workload profile '{{ workload_profile_name }}' exists
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars:
      filter: "category eq 'BIOS' and name eq '{{ workload_profile_name }}'"
    register: bios_server_setting
    delegate_to: localhost

  # - debug: var=bios_server_setting

  - name: Exit if workload profile '{{ workload_profile_name }}' does not exist
    fail:
      msg: "Workload profile '{{ workload_profile_name }}' does not exist!"
    when: bios_server_setting.json.count == 0

  - name: Set a variable for the resourceUri of workload profile '{{ workload_profile_name }}'
    set_fact: 
      bios_server_setting_resourceuri: "{{ bios_server_setting | json_query('json.items[0].resourceUri') }}"   
    
  # - debug: var=bios_server_setting_resourceuri


#--------------------------------------Create temporary server group with server settings -----------------------------------------------------------------------------

  # Create a temporary group name from hostname + _server_group

  - name: Create server group name '{{ inventory_hostname }}_server_group' variable
    set_fact:
      temporary_server_group_name: "{{ inventory_hostname }}_server_group" 

  # Group is created or modified based on whether this particular resource is present or not
  
  - name: Check if group '{{ temporary_server_group_name }}' already exists
    uri:
      url:  "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars: 
      filter: "name eq '{{ temporary_server_group_name }}'"      
    register: temporary_server_group
    delegate_to: localhost

  # - debug: var=temporary_server_group

  # Server group creation or modification when NS204i is found => no local storage configuration definition

  - name: Create temporary group '{{ temporary_server_group_name }}' with no local storage configuration definition (if it does not exist)
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"     
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'false'
            storageVolumeDeletion: 'false'
            storageVolumeName: ""
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    register: server_group_result
    when: NS204i_data is defined and temporary_server_group.json.count == 0
    delegate_to: localhost

  - name: Display response of the temporary group '{{ temporary_server_group_name }}' creation request
    debug: var=server_group_result.msg
    when:  NS204i_data is defined and temporary_server_group.json.count == 0

  - name: Set variables for the id and the resourceUri of temporary group '{{ temporary_server_group_name }}' just created
    set_fact:
      temporary_group_id: "{{ server_group_result.json.id }}" 
      temporary_group_resourceuri: "{{ server_group_result.json.resourceUri }}"
    when:  NS204i_data is defined and temporary_server_group.json.count == 0
  
  - name: Update temporary group '{{ temporary_server_group_name }}' with no local storage configuration definition (if it does exist)
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ group_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'false'
            storageVolumeDeletion: 'false'
            storageVolumeName: ""
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    vars: 
      group_id: "{{ temporary_server_group  | json_query('json.items[0].id') }}"
    register: server_group_result
    when:  NS204i_data is defined and temporary_server_group.json.count == 1
    delegate_to: localhost

  - name: Display response of the temporary group '{{ temporary_server_group_name }}' update request
    debug: var=server_group_result.msg
    when:  NS204i_data is defined and temporary_server_group.json.count == 1

  - name: Set variables for the id and the resourceUri of temporary group '{{ temporary_server_group_name }}' just updated
    set_fact:
      temporary_group_id: "{{ temporary_server_group | json_query('json.items[0].id') }}" 
      temporary_group_resourceuri: "{{ temporary_server_group | json_query('json.items[0].resourceUri') }}"
    when:  NS204i_data is defined and temporary_server_group.json.count == 1

  # Server group creation or modification when NS204i is not found => with local storage configuration definition

  - name: Create temporary group '{{ temporary_server_group_name }}' with local storage configuration definition (if it does not exist)
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
          - "{{ internal_storage_server_setting_resourceuri }}"       
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'true'
            storageVolumeDeletion: 'true'
            storageVolumeName: "OS_boot_volume"
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    register: server_group_result
    when: NS204i_data is undefined and temporary_server_group.json.count == 0
    delegate_to: localhost

  - name: Display response of the temporary group '{{ temporary_server_group_name }}' creation request
    debug: var=server_group_result.msg
    when:  NS204i_data is undefined and temporary_server_group.json.count == 0

  - name: Set variables for the id and the resourceUri of temporary group '{{ temporary_server_group_name }}' just created
    set_fact:
      temporary_group_id: "{{ server_group_result.json.id }}" 
      temporary_group_resourceuri: "{{ server_group_result.json.resourceUri }}"
    when: NS204i_data is undefined and temporary_server_group.json.count == 0
  
  - name: Update temporary group '{{ temporary_server_group_name }}' with local storage configuration definition (if it does exist)
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ group_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
          - "{{ internal_storage_server_setting_resourceuri }}"           
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'true'
            storageVolumeDeletion: 'true'
            storageVolumeName: "OS_boot_volume"
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    vars: 
      group_id: "{{ temporary_server_group  | json_query('json.items[0].id') }}"
    register: server_group_result
    when:  NS204i_data is undefined and temporary_server_group.json.count == 1
    delegate_to: localhost

  - name: Display response of the temporary group '{{ temporary_server_group_name }}' update request
    debug: var=server_group_result.msg
    when:  NS204i_data is undefined and temporary_server_group.json.count == 1

  - name: Set variables for the id and the resourceUri of temporary group '{{ temporary_server_group_name }}' just updated
    set_fact:
      temporary_group_id: "{{ temporary_server_group | json_query('json.items[0].id') }}" 
      temporary_group_resourceuri: "{{ temporary_server_group | json_query('json.items[0].resourceUri') }}"
    when: NS204i_data is undefined and temporary_server_group.json.count == 1

  - debug: var=temporary_group_id

  - debug: var=temporary_group_resourceuri


#--------------------------------------Add server to temporary server group for server configuration ------------------------------------------------------------------

  - name: Check if server '{{ serial_number }}' is already member of a server group 
    uri:
      url: "{{ ConnectivityEndpoint }}/ui-doorway/compute/v2/servers/{{ server_id }}"
      method: GET
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_info_from_ui_doorway
    delegate_to: localhost

  # - debug: var=server_info_from_ui_doorway

  - debug: var=server_info_from_ui_doorway.json.group_
    when: server_info_from_ui_doorway.json.group_ is defined

  - name: Capture the id of the server group of which the server '{{ serial_number }}' is a member (if applicable)
    set_fact:
      server_group_id_found: "{{ server_info_from_ui_doorway.json.group_.id }}"
      server_group_name_found: "{{ server_info_from_ui_doorway.json.group_.name }}"
    when: server_info_from_ui_doorway.json.group_ is not none and server_info_from_ui_doorway.json.group_ is defined

  - debug: var=server_group_name_found
    when: server_info_from_ui_doorway.json.group_ is not none and server_info_from_ui_doorway.json.group_ is defined

  - name: Remove server '{{ serial_number }}' from the server group of which it is currently a member
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ server_group_id_found }}/devices/{{ server_id }}"
      method: DELETE
      status_code: 204
      headers:
        Authorization: "Bearer {{ access_token }}"
    when: server_info_from_ui_doorway.json.group_ is not none and server_info_from_ui_doorway.json.group_ is defined
    register: group_unassignment_result
    delegate_to: localhost

  - name: Wait for deletion to complete
    pause:
      seconds: 15
    when: server_info_from_ui_doorway.json.group_ is not none and server_info_from_ui_doorway.json.group_ is defined
    
  # Add server to the temporary server group 

  - name: Assign server '{{ serial_number }}' to temporary group '{{ temporary_server_group_name }}'
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ temporary_group_id }}/devices"
      method: POST
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        devices:
          # Only servers that are not part of a group can be assigned to a group.
          - serverId: "{{ server_id }}"
    register: group_assignment_result
    delegate_to: localhost

  - name: Display response of the group assignment task
    debug: var=group_assignment_result.msg


#--------------------------------------Monitor the server configuration status ----------------------------------------------------------------------------------------
  
  # Wait for the server configuration to complete 

  - name: Wait for the configuration of server '{{ serial_number }}' to complete 
    uri:
      url:  "{{ ConnectivityEndpoint }}/compute-ops/{{ activities_API_version }}/activities?filter={{ filter | urlencode  }}"  
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars: 
      filter: "associatedServerId eq '{{ server_id }}' and createdAt gt {{ start_time }}"      
      query: "json.items[?contains(message,'Automatic configuration of server is complete') || contains(message,'configuration failed')]"
    register: server_activities
    until: server_activities | json_query(query) 
    retries: 30
    delay: 60
    delegate_to: localhost

  - name: Exit if configuration of server '{{ serial_number }}' failed to complete
    fail:
      msg: "The configuration of server '{{ serial_number }}' failed to complete! Refer to the individual server activity entries in GLCP UI for details."
    vars:
      query: "json.items[?contains(message,'configuration failed')]"
    when: server_activities | json_query(query) 

 # Capture the size of the volume created once the server configuration is complete only when NS204i is not found

  - name: Capture server '{{ serial_number }}' raw inventory information
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ servers_API_version }}/servers/{{ server_id }}/raw-inventory"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_raw_inventory
    delegate_to: localhost
    when: NS204i_data is undefined
  
  # - debug: var=server_raw_inventory
  
  - name: Capture storage RAID controller information when an HPE MR or SR controller is used with available drives
    set_fact:
      storage_controller_data: "{{ matched_item }}"
    vars:
        matched_item: "{{ item.value }}"
    loop: "{{ server_raw_inventory.json.storageInventory | dict2items }}"
    loop_control:
      label: never
    when: NS204i_data is undefined and item.value.Name == storage_controller_name 
   
  - name: Capture the size of the OS volume configured on the {{ storage_controller_name }}
    set_fact:
      boot_drive_bytes_size: "{{ (storage_controller_data |  json_query(query))[0]  }}"
    vars:
      query: "Volumes.Members[?Name=='OS_boot_volume'].CapacityBytes"
    when: NS204i_data is undefined
    
  - debug: var=boot_drive_bytes_size
        
  - debug: 
      msg: "Size of RAID volume: {{ ((boot_drive_bytes_size | int) / (1024 ** 3)) | round(1) }} GB"
    when: NS204i_data is undefined


#--------------------------------------Build ISO image with customized kickstart --------------------------------------------------------------------------------------

  - name: Check if HPE ESXi Custom ISO file '{{ src_iso_file }}' exists in '{{ src_iso_directory }}' on '{{lookup("pipe","hostname")}}' 
    stat:
      path: "{{ src_iso_directory }}/{{ src_iso_file }}"
    register: ISO_Present
    delegate_to: localhost

  - name: Create the directory '{{ src_iso_directory }}' to host the ISO file on '{{ lookup("pipe","hostname") }}'
    become: yes
    file:
      path: "{{ src_iso_directory }}"
      state: directory
    when: ISO_Present.stat.exists == False
    delegate_to: localhost

  - name: Download file '{{ src_iso_file }}' to '{{ lookup("pipe","hostname") }}' in '{{ src_iso_directory }}' if not present
    become: yes
    get_url:
      url: "{{ src_iso_url }}/{{ src_iso_file }}"
      dest: "{{ src_iso_directory }}"
      validate_certs: no
    when: ISO_Present.stat.exists == False
    delegate_to: localhost

  - name: Check if HPE ESXi Custom ISO file extraction is necessary in '{{ staging_directory }}/baremetal/{{ inventory_hostname }}' on '{{ lookup("pipe","hostname") }}'
    stat:
      path: "{{ staging_directory }}/baremetal/{{ inventory_hostname }}"
    register: ISO_Extracted
    delegate_to: localhost

  # - debug: var=ISO_Extracted

  - name: Create '/mnt/{{ inventory_hostname }}' on '{{lookup("pipe","hostname")}}' if it does not exist
    become: yes
    ansible.builtin.file:
      path: /mnt/{{ inventory_hostname }}
      state: directory
      mode: "0755"
    delegate_to: localhost

  - name: Create '{{ staging_directory }}/baremetal/{{ inventory_hostname }}/' on '{{lookup("pipe","hostname")}}' if it does not exist
    become: yes
    ansible.builtin.file:
      path: "{{ staging_directory }}/baremetal/{{ inventory_hostname }}"
      state: directory
      mode: "0755"
    delegate_to: localhost

  - name: Mount HPE ESXi Custom ISO '{{ src_iso_directory }}/{{ src_iso_file }}' to '/mnt/{{ inventory_hostname }}/' and copying ISO files to '{{ staging_directory }}/baremetal/{{ inventory_hostname }}/' on '{{lookup("pipe","hostname")}}'
    become: yes
    shell: |
      mount -o loop -t iso9660 --read-only {{ src_iso_directory }}/{{ src_iso_file }} /mnt/{{ inventory_hostname }}/
      cp -r /mnt/{{ inventory_hostname }}/. {{ staging_directory }}/baremetal/{{ inventory_hostname }}/
      umount /mnt/{{ inventory_hostname }}
    # when: ISO_Extracted.stat.exists == False
    delegate_to: localhost

  - name: Modify UEFI bootloader for kickstart installation from CDROM
    become: yes
    shell: |
      sed -i 's/kernelopt=runweasel cdromBoot/kernelopt=runweasel ks=cdrom:\/KS.CFG/' {{ staging_directory }}/baremetal/{{ inventory_hostname }}/efi/boot/boot.cfg
    delegate_to: localhost

  # Creation of the ks.tgz kickstart file

  - name: Create kickstart file 
    become: yes
    template:
      src: files/{{ esxi_build }}/{{ kickstart }}
      dest: "{{ staging_directory }}/baremetal/{{ inventory_hostname }}/KS.CFG"
    delegate_to: localhost

  - name: Prepare KS.CFG kickstart file to make the new ISO in '{{ staging_directory }}/baremetal/{{ inventory_hostname }}/KS.CFG'
    become: yes
    file:
      path: "{{ staging_directory }}/baremetal/{{ inventory_hostname }}/KS.CFG"
      state: file
      mode: "0755"
    delegate_to: localhost

  # Creation of the new ESXi ISO image with unattended installation

  - name: Create customized bootable ISO in '{{ staging_directory }}/baremetal/{{ inventory_hostname }}/'
    become: yes
    shell: >
      mkisofs
      -relaxed-filenames
      -J
      -R
      -b isolinux.bin -iso-level 2
      -c boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table
      -eltorito-alt-boot -eltorito-boot efiboot.img -no-emul-boot
      -o {{ staging_directory }}/baremetal/{{ inventory_hostname }}.iso
      {{ staging_directory }}/baremetal/{{ inventory_hostname }}/
    delegate_to: localhost

  - name: Create '/usr/share/nginx/html/isos/' on '{{lookup("pipe","hostname")}}' if it does not exist
    become: yes
    file:
      path: /usr/share/nginx/html/isos/
      state: directory
      mode: "0755"
    delegate_to: localhost

  - name: Move created ISO to the nginx default html folder 'http://{{ lookup("pipe","hostname") }}/isos'
    become: yes
    shell: |
      mv {{ staging_directory }}/baremetal/{{ inventory_hostname }}.iso /usr/share/nginx/html/isos/
    delegate_to: localhost

  - name: Update SELinux security contexts so that Nginx is allowed to serve content from the '/usr/share/nginx/html/isos/' directory.
    become: yes
    shell: |
      chcon -vR system_u:object_r:httpd_sys_content_t:s0 /usr/share/nginx/html/isos/
    delegate_to: localhost


#--------------------------------------Create OS image settings -------------------------------------------------------------------------------------------------------

  # OS image server setting is created or modified based on whether this particular resource is present or not

  - name: Check if the operating system image server setting 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' exists
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars:
      filter: "name eq 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}'"
    register: OS_image_server_setting
    delegate_to: localhost

  # - debug: var=OS_image_server_setting

  - name: Create an operating system image server setting 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' if it does not exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name:  "OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}"
        description: ""
        platformFamily: "Any"
        category:  "OS"
        settings:
          DEFAULT:
            osType: "VMWARE_ESXI"
            mediaUrl: 'http://{{ lookup("pipe","hostname") }}/isos/{{ inventory_hostname }}.iso'
    register: OS_image_server_setting_result
    delegate_to: localhost
    when: OS_image_server_setting.json.count == 0

  - name: Result of the 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' creation task
    debug: var=OS_image_server_setting_result.msg
    when: OS_image_server_setting.json.count == 0

  - name: Set variables for the id and the resourceUri of the OS Image configuration 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' just created 
    set_fact:
      OS_image_server_setting_id: "{{ OS_image_server_setting_result.json.id }}" 
      OS_image_server_setting_resourceuri: "{{ OS_image_server_setting_result.json.resourceUri }}"
    when: OS_image_server_setting.json.count == 0

  - name: Update the operating system image server setting 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' if it does not exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings/{{ OS_image_server_setting_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name:  "OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}"
        description: ""
        platformFamily: "Any"
        category:  "OS"
        settings:
          DEFAULT:
            osType: "VMWARE_ESXI"
            mediaUrl: 'http://{{ lookup("pipe","hostname") }}/isos/{{ inventory_hostname }}.iso'
    vars: 
      OS_image_server_setting_id: "{{ OS_image_server_setting  | json_query('json.items[0].id') }}"
    register: OS_image_server_setting_result
    delegate_to: localhost
    when: OS_image_server_setting.json.count == 1

  # - debug: var=OS_image_server_setting_result  

  - name: Result of the 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' update task
    debug: var=OS_image_server_setting_result.msg
    when: OS_image_server_setting.json.count == 1

  - name: Set variables for the id and the resourceUri of the OS Image configuration 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' just updated
    set_fact:
      OS_image_server_setting_id: "{{ OS_image_server_setting | json_query('json.items[0].id') }}" 
      OS_image_server_setting_resourceuri: "{{ OS_image_server_setting | json_query('json.items[0].resourceUri') }}"
    when:  OS_image_server_setting.json.count == 1

  - debug: var=OS_image_server_setting_resourceuri
  
  - debug: var=OS_image_server_setting_id


#--------------------------------------Start OS image installation-----------------------------------------------------------------------------------------------------

  # Server group modification when NS204i is found => no local storage configuration definition
  
  - name: Capture all job templates
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ job_templates_API_version }}/job-templates"
      method: GET
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: job_templates
    delegate_to: localhost

  # - debug: var=job_templates

  - name: Capture jobTemplateUri of GroupOSInstallation
    set_fact:
      job_template_resourceuri: "{{ (job_templates | json_query(query))[0] }}"
    vars:
      query: "json.items[?name=='GroupOSInstallation'].resourceUri"

  # - debug: var=job_template_resourceuri

  - name: Update temporary group '{{ temporary_server_group_name }}' to add OS image installation settings with NS204i
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ temporary_group_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
          - "{{ OS_image_server_setting_resourceuri }}"
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'false'
            storageVolumeDeletion: 'false'
            storageVolumeName: ""
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    register: server_group_result
    when:  NS204i_data is defined 
    delegate_to: localhost

  - name: Display response of the group '{{ temporary_server_group_name }}' update request with NS204i
    debug: var=server_group_result.msg
    when:  NS204i_data is defined 

  - name: Update group '{{ temporary_server_group_name }}' to add OS image installation settings with storage controller (without NS204i)
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ temporary_group_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ temporary_server_group_name }}"
        description: "Temporary server group for ESXi installation on server '{{ inventory_hostname }}'"
        autoFwUpdateOnAdd: 'false'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
          - "{{ internal_storage_server_setting_resourceuri }}"       
          - "{{ OS_image_server_setting_resourceuri }}"
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'false'
            biosApplySettings: 'true'
            storageConfiguration: 'true'
            storageVolumeDeletion: 'true'
            storageVolumeName: "OS_boot_volume"
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    register: server_group_result
    when:  NS204i_data is undefined 
    delegate_to: localhost

  - name: Display response of the group '{{ temporary_server_group_name }}' update request with storage controller
    debug: var=server_group_result.msg
    when:  NS204i_data is undefined 

  - name: Start OS image installation in group '{{ temporary_server_group_name }}'
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ jobs_API_version }}/jobs"
      method: POST
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        resourceUri: "{{ temporary_group_resourceuri }}"
        jobTemplateUri: "{{ job_template_resourceuri }}"
        data:
          devices:
            - "{{ server_id }}"
          parallel: 'true'
          stopOnFailure: 'false'
    register: group_os_installation_result
    delegate_to: localhost

  - name: Display response of the OS image installation request in group '{{ temporary_server_group_name }}' 
    debug: var=group_os_installation_result.msg


#--------------------------------------Wait for OS image installation to complete -------------------------------------------------------------------------------------
  
  # Monitor server activity

  - name: Wait for the OS image installation of server '{{ serial_number }}' to complete 
    uri:
      url:  "{{ ConnectivityEndpoint }}/compute-ops/{{ activities_API_version }}/activities?filter={{ filter | urlencode  }}"  
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars: 
      filter: "associatedServerId eq '{{ server_id }}' and createdAt gt {{ start_time }}"      
      query: "json.items[?contains(message,'Operating system image installation task marked as complete')]"
    register: server_activities
    until: server_activities | json_query(query) 
    retries: 60
    delay: 60
    delegate_to: localhost

  # - debug: var=server_activities

  - name: Exit if operating system image installation task of server '{{ serial_number }}' failed to complete
    fail:
      msg: "The operating system image installation task of server '{{ serial_number }}' failed to complete!"
    when: server_activities.attempts >= 60


#--------------------------------------Delete temporary server group and server settings ------------------------------------------------------------------------------

  # Remove server from temporary group 

  - name: Unassign server '{{ serial_number }}' from temporary group '{{ temporary_server_group_name }}' 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ temporary_group_id }}/devices/{{ server_id }}"
      method: DELETE
      status_code: 204
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: group_unassignment_result
    delegate_to: localhost

  - name: Wait for deletion to complete
    pause:
      seconds: 15

  - name: Display response of the temporary group unassignment task
    debug: var=group_unassignment_result.msg

  # Delete temporary group

  - name: Delete temporary group '{{ temporary_server_group_name }}' 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ temporary_group_id }}"
      method: DELETE
      status_code: 204
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server_group_deletion_result
    delegate_to: localhost

  - name: Display response of the temporary group deletion task
    debug: var=server_group_deletion_result.msg

  # Delete OS image server setting

  - name: Delete operating system image server setting 'OS_Image_ESXi8.0.u2_for_{{ inventory_hostname }}' 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings/{{ OS_image_server_setting_id }}"
      method: DELETE
      status_code: 204
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: OS_image_server_setting_deletion_result
    delegate_to: localhost

  - name: Display response of the operating system image server setting deletion task
    debug: var=OS_image_server_setting_deletion_result.msg


#--------------------------------------Start post-installation steps --------------------------------------------------------------------------------------------------

  - name: Wait for '{{ os_ip_address }}' to respond on port 80...
    wait_for:
      timeout: 1800
      host: "{{ os_ip_address }}"
      port: 80
    delegate_to: localhost

  - name: Wait a little longer so that the ESX host is truly ready to be added to vCenter
    wait_for:
      timeout: 60
    delegate_to: localhost

  # Backup kickstart file for troubleshooting purposes

  - name: Create a kickstart backup directory if it does not exist
    become: yes
    file:
      path: "{{ staging_directory }}/kickstarts_backup/ESXi"
      state: directory
    delegate_to: localhost

  - name: Create a backup of the kickstart file named '{{ inventory_hostname }}_ks.cfg' in '{{ staging_directory }}/kickstarts_backup/ESXi' folder
    become: yes
    shell: |
      cp -f {{ staging_directory }}/baremetal/{{ inventory_hostname }}/KS.CFG {{ staging_directory }}/kickstarts_backup/ESXi/{{ inventory_hostname }}_ks.cfg
    delegate_to: localhost

  # Cleaning up staging files

  - name: Delete all related files from staging location and nginx web server folder
    become: yes
    shell: |
      rm -rf {{ inventory_hostname }}
      rm -f /usr/share/nginx/html/isos/{{ inventory_hostname }}.iso
      rm -rf /mnt/{{ inventory_hostname }}
    args:
      chdir: "{{ staging_directory }}/baremetal"
    delegate_to: localhost

  # vCenter and ESXi configuration

  - name: Check if ESXi cluster '{{ cluster_name }}' exists in vCenter '{{ vcenter_hostname }}'
    community.vmware.vmware_cluster_info:
      hostname: '{{ vcenter_hostname }}'
      username: '{{ vcenter_username }}'
      password: '{{ vcenter_password }}'
      datacenter: "{{ datacenter_name }}"
      cluster_name: "{{ cluster_name }}"
      validate_certs: false
    register: cluster_facts
    delegate_to: localhost

  # - debug: var=cluster_facts

  - name: Create ESXi cluster '{{ cluster_name }}' in vCenter '{{ vcenter_hostname }}' if not present 
    community.vmware.vmware_cluster:
      hostname: '{{ vcenter_hostname }}'
      username: '{{ vcenter_username }}'
      password: '{{ vcenter_password }}'
      datacenter_name: "{{ datacenter_name }}"
      cluster_name: "{{ cluster_name }}"
      state: present
      validate_certs: false
    when: cluster_facts.clusters is not defined or cluster_name not in cluster_facts.clusters
    ignore_errors: yes # added as sometimes a failure is thrown saying "the name xyz already exists" when hosts are provisionned in parallel
    delegate_to: localhost

  - name: Enable HA without admission control on '{{ cluster_name }}' cluster
    community.vmware.vmware_cluster_ha:
      hostname: '{{ vcenter_hostname }}'
      username: '{{ vcenter_username }}'
      password: '{{ vcenter_password }}'
      datacenter_name: "{{ datacenter_name }}"
      cluster_name: "{{ cluster_name }}"
      enable: true
      validate_certs: false
    delegate_to: localhost

  - name: Enable DRS with VM distribution across hosts for availability on '{{ cluster_name }}' cluster
    community.vmware.vmware_cluster_drs:
      hostname: '{{ vcenter_hostname }}'
      username: '{{ vcenter_username }}'
      password: '{{ vcenter_password }}'
      datacenter_name: "{{ datacenter_name }}"
      cluster_name: "{{ cluster_name }}"
      enable: true
      advanced_settings:
        'TryBalanceVmsPerHost': '1'
      validate_certs: false
    delegate_to: localhost

  - name: Add ESXi host '{{ inventory_fqdn }}' to '{{ cluster_name }}' cluster 
    vmware_host:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      datacenter_name: "{{ datacenter_name }}"
      cluster_name: "{{ cluster_name }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      esxi_username: "root"
      esxi_password: "{{ root_password }}"
      state: present
      validate_certs: false
    delegate_to: localhost

  - name: Assign ESXi license to Host
    vcenter_license:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      license: "{{ esxi_license }}"
      state: present
      validate_certs: false
    delegate_to: localhost

  - name: Add vmnic1 to standard switch vSwitch0
    vmware_vswitch:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      switch: vSwitch0
      nics:
        - vmnic0
        - vmnic1
      validate_certs: false
    delegate_to: localhost

  - name: Pause for 10 seconds to give time for the vswitch0 configuration
    ansible.builtin.pause:
      seconds: 10

  - name: Add vMotion Portgroup to standard switch vSwitch0
    vmware_portgroup:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      switch: "vSwitch0"
      portgroup: "vMotion"
      validate_certs: false
    delegate_to: localhost

  - name: Pause for 10 seconds to give time for the vswitch0 configuration
    ansible.builtin.pause:
      seconds: 10

  - name: Change Advanced Settings with Core Dump Warning Disable
    vmware_host_config_manager:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      options:
        "UserVars.SuppressCoredumpWarning": "1"
      validate_certs: false
    delegate_to: localhost

  - name: Set the Power Management Policy to high-performance
    vmware_host_powermgmt_policy:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      policy: high-performance
      validate_certs: false
    delegate_to: localhost

  - name: Configure NTP servers
    vmware_host_ntp:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      ntp_servers:
        - pool.ntp.org
      validate_certs: false
    delegate_to: localhost

  - name: Start NTP Service and set to start at boot
    vmware_host_service_manager:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
      service_name: ntpd
      service_policy: on
      state: start
    delegate_to: localhost

  - name: Start ESXi Shell Service and setting to enable at boot
    vmware_host_service_manager:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
      service_name: TSM
      service_policy: on
      state: start
    delegate_to: localhost

  - name: Start SSH Service and setting to enable at boot
    vmware_host_service_manager:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
      service_name: TSM-SSH
      service_policy: on
      state: start
    delegate_to: localhost


#--------------------------------------Capture firmware bundle information --------------------------------------------------------------------------------------------

  - name: Collect firmware bundles
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ firmware_bundles_API_version }}/firmware-bundles"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: firmwarebundles
    delegate_to: localhost

  # - name: Display all firmware bundles
  #   debug: var=firmwarebundles

  - name: Set variable for Gen10 firmware bundle '{{ Gen10_10p_firmware_bundle_name }}'
    set_fact:
      Gen10_10p_firmware_bundle_ID:  "{{ (firmwarebundles | json_query(query) )[0] }}"
    vars:
      query: "json.items[?releaseVersion=='{{ Gen10_10p_firmware_bundle_name }}'].id"
    when: Gen10_10p_firmware_bundle_name is defined and (firmwarebundles | json_query(query) )[0] | default([]) != []

  - name:  Exit if Gen10 firmware bundle '{{ Gen10_10p_firmware_bundle_name }}' does not exist
    fail:
      msg: "Gen10 firmware bundle '{{ Gen10_10p_firmware_bundle_name }}' does not exist!"
    when: Gen10_10p_firmware_bundle_name is defined and Gen10_10p_firmware_bundle_ID is not defined

  - debug: var=Gen10_10p_firmware_bundle_ID
    when: Gen10_10p_firmware_bundle_name is defined
    
  - name: Set variable for '{{ Gen10_10p_patch_name_associated_with_firmware_bundle }}' associated patch for Gen10 firmware bundle '{{ Gen10_10p_firmware_bundle_name }}'
    set_fact:
      Gen10_10p_patch_firmware_ID: "{{ (firmwarebundles | json_query(query) )[0] }}"
    vars:
      query: "json.items[?releaseVersion=='{{ Gen10_10p_patch_name_associated_with_firmware_bundle }}'].id"
    when: Gen10_10p_patch_name_associated_with_firmware_bundle is defined and (firmwarebundles | json_query(query) )[0] | default([]) != []

  - name: Exit if Gen10 associated patch '{{ Gen10_10p_patch_name_associated_with_firmware_bundle }}' does not exist
    fail:
      msg: "Gen10 associated patch '{{ Gen10_10p_patch_name_associated_with_firmware_bundle }}' does not exist!"
    when: Gen10_10p_patch_name_associated_with_firmware_bundle is defined and Gen10_10p_patch_firmware_ID is not defined

  - debug: var=Gen10_10p_patch_firmware_ID
    when: Gen10_10p_patch_name_associated_with_firmware_bundle is defined

  - name: Set variable for Gen11 firmware bundle '{{ Gen11_firmware_bundle_name }}'
    set_fact:
      Gen11_firmware_bundle_ID:  "{{ (firmwarebundles | json_query(query) )[0] }}"
    vars:
      query: "json.items[?releaseVersion=='{{ Gen11_firmware_bundle_name }}'].id"
    when: Gen11_firmware_bundle_name is defined and (firmwarebundles | json_query(query) )[0] | default([]) != []

  - name: Exit if Gen11 firmware bundle '{{ Gen11_firmware_bundle_name }}' does not exist
    fail:
      msg: "Gen11 firmware bundle '{{ Gen11_firmware_bundle_name }}' does not exist!"
    when: Gen11_firmware_bundle_name is defined and Gen11_firmware_bundle_ID is not defined

  - debug: var=Gen11_firmware_bundle_ID
    when: Gen11_firmware_bundle_name is defined

  - name: Set variable for '{{ Gen11_patch_name_associated_with_firmware_bundle }}' associated patch for Gen10 firmware bundle '{{ Gen11_firmware_bundle_name }}'
    set_fact:
      Gen11_patch_firmware_ID:  "{{ (firmwarebundles | json_query(query) )[0] }}"
    vars:
      query: "json.items[?releaseVersion=='{{ Gen11_patch_name_associated_with_firmware_bundle }}'].id"
    when: Gen11_patch_name_associated_with_firmware_bundle is defined and (firmwarebundles | json_query(query) )[0] | default([]) != []

  - name: Exit if Gen11 associated patch '{{ Gen11_patch_name_associated_with_firmware_bundle }}' does not exist
    fail:
      msg: "Gen11 associated patch '{{ Gen10_10p_patch_name_associated_with_firmware_bundle }}' does not exist!"
    when: Gen11_patch_name_associated_with_firmware_bundle is defined and Gen11_patch_firmware_ID is not defined

  - debug: var=Gen11_patch_firmware_ID
    when: Gen11_patch_name_associated_with_firmware_bundle is defined

  - name: Set the final variable value for the Gen10 firmware bundle ID
    set_fact:
      Gen10_10p_firmware_bundle_ID: "{{ Gen10_10p_patch_firmware_ID }}"
    when: Gen10_10p_patch_firmware_ID is defined

  - name: Set the final variable value for the Gen11 firmware bundle ID
    set_fact:
      Gen11_firmware_bundle_ID: "{{ Gen11_patch_firmware_ID }}"
    when: Gen11_patch_firmware_ID is defined


 # Create the firmware server setting 

  - name: Check if the firmware server setting '{{ firmware_server_setting_name }}' exists
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars:
      filter: "name eq '{{ firmware_server_setting_name }}'"
    register: firmware_server_setting
    delegate_to: localhost

  # - debug: var=firmware_server_setting

  - name: Create the firmware server setting '{{ firmware_server_setting_name }}' 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name: "{{ firmware_server_setting_name }}"
        description: "Firmware baseline for ESXi 8.0.u2"
        category: "FIRMWARE"
        platformFamily: "Any"
        settings:
          GEN10:
            id: "{{ Gen10_10p_firmware_bundle_ID }}"
          GEN11:
            id: "{{ Gen11_firmware_bundle_ID }}"
    register: firmware_server_setting_result
    when: firmware_server_setting.json.count == 0
    delegate_to: localhost

  - name: Display response of the firmware server setting '{{ firmware_server_setting_name }}' creation request
    debug: var=firmware_server_setting_result.msg
    when: firmware_server_setting.json.count == 0

  - name: Set variable for the resourceuri of the firmware server setting '{{ firmware_server_setting_name }}' just created
    set_fact: 
      firmware_server_setting_resourceuri: "{{ firmware_server_setting_result.json.resourceUri }}"
    when: firmware_server_setting.json.count == 0

  - name: Update the firmware server setting '{{ firmware_server_setting_name }}' 
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ server_settings_API_version }}/server-settings/{{ firmware_server_setting_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ firmware_server_setting_name }}"
        description: "Firmware baseline for ESXi 8.0.u2"
        category: "FIRMWARE"
        platformFamily: "Any"
        settings:
          GEN10:
            id: "{{ Gen10_10p_firmware_bundle_ID }}"
          GEN11:
            id: "{{ Gen11_firmware_bundle_ID }}"
    vars: 
      firmware_server_setting_id: "{{ firmware_server_setting | json_query('json.items[0].id')  }}"
    register: firmware_server_setting_result
    when: firmware_server_setting.json.count == 1
    delegate_to: localhost

  - name: Display response of the firmware server setting '{{ firmware_server_setting_name }}' update task
    debug: var=firmware_server_setting_result.msg
    when: firmware_server_setting.json.count == 1
    
  - name: Set variable for the resourceuri of the firmware server setting '{{ firmware_server_setting_name }}' just updated
    set_fact: 
      firmware_server_setting_resourceuri: "{{ firmware_server_setting | json_query('json.items[0].resourceUri') }}"
    when: firmware_server_setting.json.count == 1

  - debug: var=firmware_server_setting_resourceuri


#--------------------------------------Firmware update preparation: Create a definitive server group or update if existing --------------------------------------------

 # Check if definitive server group exists
  
  - name: Check if definitive group '{{ server_group_name }}' already exist
    uri:
      url:  "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups?filter={{ filter | urlencode }}"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars: 
      filter: "name eq '{{ server_group_name }}'"      
    register: definitive_server_group
    delegate_to: localhost

  # - debug: var=definitive_server_group

  # Create the definitive server group if it does not exist

  - name: Create definitive group '{{ server_group_name }}' if it does not exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups"
      method: POST
      status_code: 201
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        name: "{{ server_group_name }}"
        description: "Server group for ESXi servers"
        autoFwUpdateOnAdd: 'true'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"     
          - "{{ firmware_server_setting_resourceuri }}"     
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'true'
            biosApplySettings: 'false'
            storageConfiguration: 'false'
            storageVolumeDeletion: 'false'
            storageVolumeName: ""
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    register: definitive_server_group_result
    when: definitive_server_group.json.count == 0
    delegate_to: localhost

  - name: Display response of the definitive group '{{ server_group_name }}' creation request
    debug: var=definitive_server_group_result.msg
    when:  definitive_server_group.json.count == 0

  - name: Set variables for the id and the resourceUri of the definitive group '{{ server_group_name }}' just created
    set_fact:
      definitive_group_id: "{{ definitive_server_group_result.json.id }}" 
      definitive_group_resourceuri: "{{ definitive_server_group_result.json.resourceUri }}"
    when:  definitive_server_group.json.count == 0

  # Update the definitive server group if the group exists
    
  - name: Update definitive group '{{ server_group_name }}' if it does exist
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ group_id }}"
      method: PATCH
      status_code: 200
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/merge-patch+json"
      body_format: json
      body:
        name: "{{ server_group_name }}"
        description: "Server group for ESXi server"
        autoFwUpdateOnAdd: 'true'
        serverSettingsUris: 
          - "{{ bios_server_setting_resourceuri }}"   
          - "{{ firmware_server_setting_resourceuri }}"     
        serverPolicies:
          onServerAdd:
            firmwareUpdate: 'true'
            biosApplySettings: 'false'
            storageConfiguration: 'false'
            storageVolumeDeletion: 'false'
            storageVolumeName: ""
            osInstall: 'false'
          onSettingsApply:
            firmwareDowngrade: 'false'
        autoAddServerTags:
    vars: 
      group_id: "{{ definitive_server_group  | json_query('json.items[0].id') }}"
    register: definitive_server_group_result
    when: definitive_server_group.json.count == 1
    delegate_to: localhost

  - name: Display response of the group '{{ server_group_name }}' update request
    debug: var=definitive_server_group_result.msg
    when: definitive_server_group.json.count == 1

  - name: Set variables for the id and the resourceUri of the existing definitive group '{{ server_group_name }}' just updated
    set_fact:
      definitive_group_id: "{{ definitive_server_group | json_query('json.items[0].id') }}" 
      definitive_group_resourceuri: "{{ definitive_server_group | json_query('json.items[0].resourceUri') }}"
    when:  definitive_server_group.json.count == 1

  - debug: var=definitive_group_id  

  - debug: var=definitive_group_resourceuri


#--------------------------------------Firmware update preparation: Put server in maintenance mode --------------------------------------------------------------------
  
  # Capture the start time of the firmware update
  - name: Gather subset facts on localhost
    setup:
      gather_subset: [all]
    delegate_to: localhost

  - name: Capture the start time (will be used later to filter COM activities and get the runtime of the playbook)
    set_fact:
      firmware_update_start_time: "{{ ansible_date_time.iso8601 }}"

  - name: Place ESXi host '{{ inventory_fqdn }}' into maintenance mode
    community.vmware.vmware_maintenancemode:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
      evacuate: true
      timeout: 3600
      state: present
    delegate_to: localhost


#--------------------------------------Start firmware update by adding server to definitive server group --------------------------------------------------------------
      
  # Check if the server is already member of the definitive server group if it does exist

  - name: Check if server '{{ serial_number }}' is already member of definitive server group '{{ server_group_name }}' 
    set_fact: 
      server_found_in_definitive_group: "{{ definitive_server_group  | json_query(query) }}"
    vars:
      query: "json.items[0].devices[?serial=='{{ serial_number }}']"
    when: definitive_server_group.json.count == 1
      
  # - debug: var=server_found_in_definitive_group  

  # Remove the server from the definitive server group if it's already part of it (which shouldn't be the case, unless the playbook has failed and been rerun)

  - name: Remove server '{{ serial_number }}' from definitive server group '{{ server_group_name }}' if it is already a member
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ definitive_group_id }}/devices/{{ server_id }}"
      method: DELETE
      status_code: 204
      headers:
        Authorization: "Bearer {{ access_token }}"
    when: server_found_in_definitive_group | length != 0
    register: group_unassignment_result
    delegate_to: localhost

  - name: Wait for deletion to complete
    pause:
      seconds: 15
    when: server_found_in_definitive_group | length != 0
    
  # Add server to the definitive server group 

  - name: Assign server '{{ serial_number }}' to definitive server group '{{ server_group_name }}'
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ groups_API_version }}/groups/{{ definitive_group_id }}/devices"
      method: POST
      headers:
        Authorization: "Bearer {{ access_token }}"
        Content-Type: "application/json"
      body_format: json
      body:
        devices:
          - serverId: "{{ server_id }}"
    register: group_assignment_result
    delegate_to: localhost

  - name: Display response of the group assignment task
    debug: var=group_assignment_result.msg


#--------------------------------------Wait for the server firmware update to complete --------------------------------------------------------------------------------
  
  # Monitor the server firmware update status

  - name: Wait for the firmware update of server '{{ serial_number }}' to complete 
    uri:
      url:  "{{ ConnectivityEndpoint }}/compute-ops/{{ activities_API_version }}/activities?filter={{ filter | urlencode  }}"  
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    vars: 
      filter: "associatedServerId eq '{{ server_id }}' and createdAt gt {{ firmware_update_start_time }}"      
      query: "json.items[?contains(message,'complete') || contains(message,'Firmware update failed')]"
    register: server_activities
    until: server_activities | json_query(query) 
    retries: 1000
    delay: 60
    delegate_to: localhost

  # Capture last firmware update information

  - name: Capture server '{{ serial_number }}' information   
    uri:
      url: "{{ ConnectivityEndpoint }}/compute-ops/{{ servers_API_version }}/servers?filter=hardware/serialNumber%20eq%20'{{ serial_number }}'"
      method: GET
      headers:
        Authorization: "Bearer {{ access_token }}"
    register: server
    delegate_to: localhost

  - name: Display last firmware update information
    debug: 
      msg: "{{ server | json_query('json.items[0].lastFirmwareUpdate') }}"  

  - name: Exit if configuration of server '{{ serial_number }}' failed to complete
    fail:
      msg: 
        - "The configuration of server '{{ serial_number }}' failed to complete! Refer to the individual server activity entries in GLCP UI for details."
        - "The server will remain in maintenance mode!"
    vars:
      query: "json.items[?contains(message,'Firmware update failed')]"
    when: server_activities | json_query(query) 


#--------------------------------------Exit ESXi server from maintenance mode -----------------------------------------------------------------------------------------

  # Wait until the ESXi host is accessible again if a reboot was necessary to activate some firmware components

  - name: Wait until VMware host is 'connected' in vCenter
    community.vmware.vmware_host_facts:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
    register: host_facts 
    delegate_to: localhost
    delay: 10
    timeout: 900 # 15 minutes
    until: host_facts.ansible_facts.ansible_host_connection_state == "connected"

  - name: Take ESXi host '{{ inventory_fqdn }}' out of maintenance mode
    community.vmware.vmware_maintenancemode:
      hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_username }}"
      password: "{{ vcenter_password }}"
      esxi_hostname: "{{ inventory_fqdn }}"
      validate_certs: false
      state: absent
    delegate_to: localhost


#--------------------------------------Display end-of-installation message --------------------------------------------------------------------------------------------

  # Get the runtime

  - name: Force update of current timestamp
    setup: filter='ansible_date_time'
    delegate_to: localhost

  - name: Get runtime
    set_fact:
      runtime: "{{ ((ansible_date_time.iso8601[:19] | to_datetime('%Y-%m-%dT%H:%M:%S')) - (start_time[:19] | to_datetime('%Y-%m-%dT%H:%M:%S'))) }}"

  # Display ESXi server installation completion message

  - name: Displaying install completion message
    debug:
      msg:
        - "{{ inventory_hostname }}.{{domain}} Installation completed !"
        - "ESXi is configured and running. It has been added to the vCenter cluster '{{ cluster_name }}'"
        - "To connect to the new host from Ansible control node, use: ssh root@{{ inventory_hostname }}.{{domain}}"
        - "The provisioning task took {{ runtime }}"
